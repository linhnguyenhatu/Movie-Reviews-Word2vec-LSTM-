{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e-iOKwXux4O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qqRwYvGJZn2",
        "outputId": "73f68bad-ebfe-487f-8ad5-80f17649a232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: torchtext==0.18.0 in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchtext==0.18.0) (12.6.77)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext==0.18.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchtext==0.18.0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.3.0\n",
        "!pip install torchtext==0.18.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dnXCMDWz7XR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46506a54-35c7-4c56-e47f-d1104dba6190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import sklearn as sk\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import re\n",
        "import torchtext.vocab as tvc\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7oxskrGvW7e",
        "outputId": "b2da048e-7fae-4ade-ca0c-a9d47c0ca78a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q4T-VUs9NcN",
        "outputId": "f203b4b5-b590-4a19-9f5e-6aa27fe76d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "wordnet = WordNetLemmatizer()\n",
        "data = pd.read_csv(\"sample_data/train.csv\")\n",
        "def clean_data(text, stop_words, max_length):\n",
        "  text = text.lower()\n",
        "  text = text.replace(\"'\",\"\")\n",
        "  text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "  text = text.split()\n",
        "  text = [word for word in text if word not in stop_words]\n",
        "\n",
        "  text = [wordnet.lemmatize(word) for word in text]\n",
        "  text = text[:max_length]\n",
        "  text\n",
        "  return text\n",
        "data[\"text\"] = data[\"text\"].apply(clean_data, stop_words = [\"http\", \"com\"], max_length = 1000)\n",
        "\n",
        "\n",
        "print(type(data[\"text\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k4Zt_KvnMyUO"
      },
      "outputs": [],
      "source": [
        "dataset_y = data[\"sentiment\"].tolist()\n",
        "dataset_x = data[\"text\"].tolist()\n",
        "X_train = dataset_x\n",
        "Y_train = dataset_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f_ctQO0O1hH",
        "outputId": "dde3a91a-5424-463a-fa7a-0ba4fae6dd5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "min_freq = 2\n",
        "\n",
        "unk_token = \"<unk>\"\n",
        "pad_token = \"<pad>\"\n",
        "\n",
        "special_tokens = [unk_token, pad_token]\n",
        "special_tokens_output = []\n",
        "Y_train = np.array(Y_train).reshape(-1,1)\n",
        "input_train_dataset = torch.load(\"movie-rating-LLM-input.pt\")\n",
        "output_train_dataset = torch.load(\"movie-rating-LLM-output.pt\")\n",
        "input_train_dataset.set_default_index(input_train_dataset[unk_token])\n",
        "\n",
        "Y_train = Y_train.tolist()\n",
        "len(output_train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "otA4PoROULzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa3c5b23-728f-420b-95bf-b3ef94a2cb8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([25000, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "for i in range(len(Y_train)):\n",
        "  X_train[i] = torch.tensor(input_train_dataset.lookup_indices(X_train[i]))\n",
        "  Y_train[i] = torch.tensor(output_train_dataset.lookup_indices(Y_train[i]))\n",
        "X_train = nn.utils.rnn.pad_sequence(X_train, padding_value = 0, batch_first = True)\n",
        "X_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ON7G_FtzVAP9"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx]\n",
        "data = CustomDataset(X_train, Y_train)\n",
        "dataloader = DataLoader(data, batch_size = 32, num_workers = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Iq68t8h4Y3lT"
      },
      "outputs": [],
      "source": [
        "class Encode(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers,embedding_size, dropout):\n",
        "    super(Encode, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first = True, dropout = dropout)\n",
        "    self.ReLU = nn.ReLU()\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "    self.fc1 = nn.Linear(1000, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    output, (hidden, cell) = self.lstm(embedding)\n",
        "    output = self.fc(output)\n",
        "    out = self.fc1(output.reshape(-1,1000))\n",
        "    out = torch.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "input_size = len(input_train_dataset)\n",
        "hidden_size = 100\n",
        "output_size = 1\n",
        "num_layers = 2\n",
        "embedding_size = 128\n",
        "dropout = 0.5\n",
        "model = Encode(input_size, hidden_size, output_size, num_layers, embedding_size, dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LVyDwA4veckQ",
        "outputId": "741a303c-a258-452e-c88d-af3bb6c8f610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-3b2de5afacf6>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  output = torch.tensor(output, dtype = torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12, Loss: 0.06922490894794464\n",
            "Epoch: 12, Loss: 0.04316394962370396\n",
            "Epoch: 12, Loss: 0.05802527442574501\n",
            "Epoch: 12, Loss: 0.04913770407438278\n",
            "Epoch: 12, Loss: 0.04374914318323135\n",
            "Epoch: 12, Loss: 0.04229325739045938\n",
            "Epoch: 12, Loss: 0.062330130487680435\n",
            "Epoch: 12, Loss: 0.06290094973519444\n",
            "Epoch: 12, Loss: 0.06308882062633832\n",
            "Epoch: 12, Loss: 0.06653873287141324\n",
            "Epoch: 12, Loss: 0.08118574964729222\n",
            "Epoch: 12, Loss: 0.11179482657462358\n",
            "Epoch: 12, Loss: 0.11224749139868297\n",
            "Epoch: 12, Loss: 0.11377218285841602\n",
            "Epoch: 12, Loss: 0.10985500638683637\n",
            "Epoch: 12, Loss: 0.10452110425103456\n",
            "Epoch: 12, Loss: 0.10588105209171772\n",
            "Epoch: 12, Loss: 0.10411515014453067\n",
            "Epoch: 12, Loss: 0.10362685324722215\n",
            "Epoch: 12, Loss: 0.1010638858191669\n",
            "Epoch: 12, Loss: 0.0964707598045823\n",
            "Epoch: 12, Loss: 0.09327155087058517\n",
            "Epoch: 12, Loss: 0.09065943687101422\n",
            "Epoch: 12, Loss: 0.09617214640214418\n",
            "Epoch: 12, Loss: 0.09748644163832068\n",
            "Epoch: 12, Loss: 0.09479152352119294\n",
            "Epoch: 12, Loss: 0.09804793307557702\n",
            "Epoch: 12, Loss: 0.10168855848522591\n",
            "Epoch: 12, Loss: 0.10135703866273679\n",
            "Epoch: 12, Loss: 0.10152629289465646\n",
            "Epoch: 12, Loss: 0.10403290846114678\n",
            "Epoch: 12, Loss: 0.10110592264391016\n",
            "Epoch: 12, Loss: 0.09867835478066947\n",
            "Epoch: 12, Loss: 0.09693513694219291\n",
            "Epoch: 12, Loss: 0.09504595088905522\n",
            "Epoch: 12, Loss: 0.09428247839160678\n",
            "Epoch: 12, Loss: 0.09629090924470408\n",
            "Epoch: 12, Loss: 0.09676560846549508\n",
            "Epoch: 12, Loss: 0.10025922886024301\n",
            "Epoch: 12, Loss: 0.10078914248151705\n",
            "Epoch: 12, Loss: 0.10283086438686019\n",
            "Epoch: 12, Loss: 0.10420847301637488\n",
            "Epoch: 12, Loss: 0.10308381914009535\n",
            "Epoch: 12, Loss: 0.10133564805569635\n",
            "Epoch: 12, Loss: 0.10167071151857575\n",
            "Epoch: 12, Loss: 0.10024483853181743\n",
            "Epoch: 12, Loss: 0.09932050413075597\n",
            "Epoch: 12, Loss: 0.09825452427806643\n",
            "Epoch: 12, Loss: 0.09846745745982138\n",
            "Epoch: 12, Loss: 0.09936961392872036\n",
            "Epoch: 12, Loss: 0.09887167996745191\n",
            "Epoch: 12, Loss: 0.10078248420121291\n",
            "Epoch: 12, Loss: 0.10078838364801036\n",
            "Epoch: 12, Loss: 0.10029685479174885\n",
            "Epoch: 12, Loss: 0.09988036842339418\n",
            "Epoch: 12, Loss: 0.09888758293319759\n",
            "Epoch: 12, Loss: 0.09748942704805941\n",
            "Epoch: 12, Loss: 0.09702462779261686\n",
            "Epoch: 12, Loss: 0.0966934036321433\n",
            "Epoch: 12, Loss: 0.09575370536961904\n",
            "Epoch: 12, Loss: 0.09463604844221082\n",
            "Epoch: 12, Loss: 0.09523219830777135\n",
            "Epoch: 12, Loss: 0.09480460353993944\n",
            "Epoch: 12, Loss: 0.09424316649528919\n",
            "Epoch: 12, Loss: 0.09363584970482267\n",
            "Epoch: 12, Loss: 0.09295591671781783\n",
            "Epoch: 12, Loss: 0.09208632104182199\n",
            "Epoch: 12, Loss: 0.09160706498797107\n",
            "Epoch: 12, Loss: 0.09200851920911152\n",
            "Epoch: 12, Loss: 0.09130708233985518\n",
            "Epoch: 12, Loss: 0.09036451152486491\n",
            "Epoch: 12, Loss: 0.08935981248376063\n",
            "Epoch: 12, Loss: 0.08883243660786994\n",
            "Epoch: 12, Loss: 0.09015548716903336\n",
            "Epoch: 12, Loss: 0.08909889860078693\n",
            "Epoch: 12, Loss: 0.08878952738412313\n",
            "Epoch: 12, Loss: 0.0888788227245889\n",
            "Epoch: 12, Loss: 0.09017307782330765\n",
            "Epoch: 12, Loss: 0.08912908878248138\n",
            "Epoch: 12, Loss: 0.0882234126154799\n",
            "Epoch: 12, Loss: 0.0889109299334203\n",
            "Epoch: 12, Loss: 0.08800459142615337\n",
            "Epoch: 12, Loss: 0.0878723197145365\n",
            "Epoch: 12, Loss: 0.08721299113018349\n",
            "Epoch: 12, Loss: 0.08656843601013808\n",
            "Epoch: 12, Loss: 0.08697891181746367\n",
            "Epoch: 12, Loss: 0.08639706344204559\n",
            "Epoch: 12, Loss: 0.08598293294727971\n",
            "Epoch: 12, Loss: 0.08757950380716599\n",
            "Epoch: 12, Loss: 0.08670772769902316\n",
            "Epoch: 12, Loss: 0.0868598117165595\n",
            "Epoch: 12, Loss: 0.08733672673469814\n",
            "Epoch: 12, Loss: 0.08705537983026075\n",
            "Epoch: 12, Loss: 0.08676451080518359\n",
            "Epoch: 12, Loss: 0.08672246157044643\n",
            "Epoch: 12, Loss: 0.08598003088748858\n",
            "Epoch: 12, Loss: 0.08593152826843956\n",
            "Epoch: 12, Loss: 0.08618542698820178\n",
            "Epoch: 12, Loss: 0.08737715682240599\n",
            "Epoch: 12, Loss: 0.08757537762168795\n",
            "Epoch: 12, Loss: 0.08806240597813583\n",
            "Epoch: 12, Loss: 0.08756386560351387\n",
            "Epoch: 12, Loss: 0.08732925064735186\n",
            "Epoch: 12, Loss: 0.08707174772056393\n",
            "Epoch: 12, Loss: 0.08823015149239273\n",
            "Epoch: 12, Loss: 0.0879164281397847\n",
            "Epoch: 12, Loss: 0.08825631246893345\n",
            "Epoch: 12, Loss: 0.08786361232072253\n",
            "Epoch: 12, Loss: 0.08828554113198994\n",
            "Epoch: 12, Loss: 0.08816801955161446\n",
            "Epoch: 12, Loss: 0.0884078319755022\n",
            "Epoch: 12, Loss: 0.08869273071260457\n",
            "Epoch: 12, Loss: 0.0886723170576172\n",
            "Epoch: 12, Loss: 0.08865955460963673\n",
            "Epoch: 12, Loss: 0.08872322597662392\n",
            "Epoch: 12, Loss: 0.08886268178145562\n",
            "Epoch: 12, Loss: 0.08920570796069044\n",
            "Epoch: 12, Loss: 0.08856099860158638\n",
            "Epoch: 12, Loss: 0.08867605071624413\n",
            "Epoch: 12, Loss: 0.08833096794551239\n",
            "Epoch: 12, Loss: 0.0883596228274001\n",
            "Epoch: 12, Loss: 0.08871677667894935\n",
            "Epoch: 12, Loss: 0.0882136985334015\n",
            "Epoch: 12, Loss: 0.08847463912435717\n",
            "Epoch: 12, Loss: 0.08823951515927911\n",
            "Epoch: 12, Loss: 0.08764123177850648\n",
            "Epoch: 12, Loss: 0.08725626567583972\n",
            "Epoch: 12, Loss: 0.08739313279875205\n",
            "Epoch: 12, Loss: 0.08700165617850053\n",
            "Epoch: 12, Loss: 0.0882218327982208\n",
            "Epoch: 12, Loss: 0.08840438550451898\n",
            "Epoch: 12, Loss: 0.08794524375645613\n",
            "Epoch: 12, Loss: 0.08798974995060187\n",
            "Epoch: 12, Loss: 0.08796765518013332\n",
            "Epoch: 12, Loss: 0.08760790310593115\n",
            "Epoch: 12, Loss: 0.08712615819497253\n",
            "Epoch: 12, Loss: 0.08705638269180038\n",
            "Epoch: 12, Loss: 0.08828761759619026\n",
            "Epoch: 12, Loss: 0.08845541445645604\n",
            "Epoch: 12, Loss: 0.08984100336009371\n",
            "Epoch: 12, Loss: 0.09043419103844898\n",
            "Epoch: 12, Loss: 0.09025630130904766\n",
            "Epoch: 12, Loss: 0.09024042554421129\n",
            "Epoch: 12, Loss: 0.08993624173065957\n",
            "Epoch: 12, Loss: 0.09128752722372782\n",
            "Epoch: 12, Loss: 0.0914479895360921\n",
            "Epoch: 12, Loss: 0.09093065261777465\n",
            "Epoch: 12, Loss: 0.09092401281137623\n",
            "Epoch: 12, Loss: 0.09042370281551008\n",
            "Epoch: 12, Loss: 0.09049629938788711\n",
            "Epoch: 12, Loss: 0.0908169117016064\n",
            "Epoch: 12, Loss: 0.09027849953609372\n",
            "Epoch: 12, Loss: 0.09040064400889808\n",
            "Epoch: 12, Loss: 0.09021202576128984\n",
            "Epoch: 12, Loss: 0.08989362540925222\n",
            "Epoch: 12, Loss: 0.08996321864796276\n",
            "Epoch: 12, Loss: 0.09009242463251872\n",
            "Epoch: 12, Loss: 0.08980600240852542\n",
            "Epoch: 12, Loss: 0.09125175741471865\n",
            "Epoch: 12, Loss: 0.0931153879238991\n",
            "Epoch: 12, Loss: 0.0928938629898179\n",
            "Epoch: 12, Loss: 0.09275450580178496\n",
            "Epoch: 12, Loss: 0.0923859966558867\n",
            "Epoch: 12, Loss: 0.0922215555016542\n",
            "Epoch: 12, Loss: 0.09189926613630219\n",
            "Epoch: 12, Loss: 0.09151891840857465\n",
            "Epoch: 12, Loss: 0.09194128534026043\n",
            "Epoch: 12, Loss: 0.09154645976377651\n",
            "Epoch: 12, Loss: 0.09181769282320107\n",
            "Epoch: 12, Loss: 0.09137190598720575\n",
            "Epoch: 12, Loss: 0.09114140630236756\n",
            "Epoch: 12, Loss: 0.09236175732329747\n",
            "Epoch: 12, Loss: 0.09274862983097144\n",
            "Epoch: 12, Loss: 0.09270842840905762\n",
            "Epoch: 12, Loss: 0.09254976430907845\n",
            "Epoch: 12, Loss: 0.09245448894745839\n",
            "Epoch: 12, Loss: 0.09312709909995313\n",
            "Epoch: 12, Loss: 0.09339733878830762\n",
            "Epoch: 12, Loss: 0.09325612974014945\n",
            "Epoch: 12, Loss: 0.0930988391318048\n",
            "Epoch: 12, Loss: 0.0927274170619801\n",
            "Epoch: 12, Loss: 0.09252119189957259\n",
            "Epoch: 12, Loss: 0.09233492086361585\n",
            "Epoch: 12, Loss: 0.09209498818508229\n",
            "Epoch: 12, Loss: 0.09264214835003824\n",
            "Epoch: 12, Loss: 0.09285161298479364\n",
            "Epoch: 12, Loss: 0.09294366062354835\n",
            "Epoch: 12, Loss: 0.09319631833375056\n",
            "Epoch: 12, Loss: 0.09300495785409732\n",
            "Epoch: 12, Loss: 0.09282528090192692\n",
            "Epoch: 12, Loss: 0.09316583811329844\n",
            "Epoch: 12, Loss: 0.09299874905991601\n",
            "Epoch: 12, Loss: 0.09292676290883224\n",
            "Epoch: 12, Loss: 0.0930303625027966\n",
            "Epoch: 12, Loss: 0.09300439685153274\n",
            "Epoch: 12, Loss: 0.09348664378357709\n",
            "Epoch: 12, Loss: 0.09331743036004417\n",
            "Epoch: 12, Loss: 0.09331934611933927\n",
            "Epoch: 12, Loss: 0.09428456971122318\n",
            "Epoch: 12, Loss: 0.09410288297338411\n",
            "Epoch: 12, Loss: 0.0936737689096944\n",
            "Epoch: 12, Loss: 0.09337183341411597\n",
            "Epoch: 12, Loss: 0.09335394011663613\n",
            "Epoch: 12, Loss: 0.09315483745726227\n",
            "Epoch: 12, Loss: 0.09380980714383286\n",
            "Epoch: 12, Loss: 0.09432967743854427\n",
            "Epoch: 12, Loss: 0.09407846412535954\n",
            "Epoch: 12, Loss: 0.09450756356146975\n",
            "Epoch: 12, Loss: 0.09463601255272493\n",
            "Epoch: 12, Loss: 0.0944879590999335\n",
            "Epoch: 12, Loss: 0.09444898697746237\n",
            "Epoch: 12, Loss: 0.09427836204149742\n",
            "Epoch: 12, Loss: 0.09419316036556738\n",
            "Epoch: 12, Loss: 0.09383553907788733\n",
            "Epoch: 12, Loss: 0.09403171720156489\n",
            "Epoch: 12, Loss: 0.09385894622472632\n",
            "Epoch: 12, Loss: 0.09380678417727625\n",
            "Epoch: 12, Loss: 0.09405003669842599\n",
            "Epoch: 12, Loss: 0.0942240031202192\n",
            "Epoch: 12, Loss: 0.09452847632452507\n",
            "Epoch: 12, Loss: 0.09426282378908128\n",
            "Epoch: 12, Loss: 0.09407331645782399\n",
            "Epoch: 12, Loss: 0.09405542474716166\n",
            "Epoch: 12, Loss: 0.09381765561868503\n",
            "Epoch: 12, Loss: 0.09353824914950463\n",
            "Epoch: 12, Loss: 0.09324675145460111\n",
            "Epoch: 12, Loss: 0.09317150518158655\n",
            "Epoch: 12, Loss: 0.09299476480462768\n",
            "Epoch: 12, Loss: 0.09275264409879085\n",
            "Epoch: 12, Loss: 0.09327755651193792\n",
            "Epoch: 12, Loss: 0.0934696197812143\n",
            "Epoch: 12, Loss: 0.09402994743893565\n",
            "Epoch: 12, Loss: 0.09409445600760022\n",
            "Epoch: 12, Loss: 0.0942948126874896\n",
            "Epoch: 12, Loss: 0.09415408735698524\n",
            "Epoch: 12, Loss: 0.09452350666328191\n",
            "Epoch: 12, Loss: 0.09455919285984671\n",
            "Epoch: 12, Loss: 0.09513089024587025\n",
            "Epoch: 12, Loss: 0.09485291976240078\n",
            "Epoch: 12, Loss: 0.09505078112512516\n",
            "Epoch: 12, Loss: 0.09494906898657501\n",
            "Epoch: 12, Loss: 0.09467115957282238\n",
            "Epoch: 12, Loss: 0.09451157554271228\n",
            "Epoch: 12, Loss: 0.09442969989298736\n",
            "Epoch: 12, Loss: 0.09440887388488164\n",
            "Epoch: 12, Loss: 0.0944900966147188\n",
            "Epoch: 12, Loss: 0.09459358451299761\n",
            "Epoch: 12, Loss: 0.09456598230509929\n",
            "Epoch: 12, Loss: 0.09427722447540567\n",
            "Epoch: 12, Loss: 0.09397576322220266\n",
            "Epoch: 12, Loss: 0.09395163045246228\n",
            "Epoch: 12, Loss: 0.09375393335034864\n",
            "Epoch: 12, Loss: 0.09389000904853106\n",
            "Epoch: 12, Loss: 0.09429323588732601\n",
            "Epoch: 12, Loss: 0.09408807774056115\n",
            "Epoch: 12, Loss: 0.09404684998116863\n",
            "Epoch: 12, Loss: 0.09404195957284435\n",
            "Epoch: 12, Loss: 0.09450783715366798\n",
            "Epoch: 12, Loss: 0.09458367528508932\n",
            "Epoch: 12, Loss: 0.09437302557858997\n",
            "Epoch: 12, Loss: 0.094114748887732\n",
            "Epoch: 12, Loss: 0.09403657481493784\n",
            "Epoch: 12, Loss: 0.09386936230089218\n",
            "Epoch: 12, Loss: 0.09389420407365612\n",
            "Epoch: 12, Loss: 0.09358589647618948\n",
            "Epoch: 12, Loss: 0.09346303830966633\n",
            "Epoch: 12, Loss: 0.0932921824422194\n",
            "Epoch: 12, Loss: 0.09314646846927535\n",
            "Epoch: 12, Loss: 0.09319263364129517\n",
            "Epoch: 12, Loss: 0.09349951081633291\n",
            "Epoch: 12, Loss: 0.0935507572867746\n",
            "Epoch: 12, Loss: 0.09385614025728393\n",
            "Epoch: 12, Loss: 0.09370777612524755\n",
            "Epoch: 12, Loss: 0.09361045607569607\n",
            "Epoch: 12, Loss: 0.09367106568914922\n",
            "Epoch: 12, Loss: 0.09355580057456171\n",
            "Epoch: 12, Loss: 0.09340526792809152\n",
            "Epoch: 12, Loss: 0.09311577778396686\n",
            "Epoch: 12, Loss: 0.09294632360452659\n",
            "Epoch: 12, Loss: 0.09320204396499321\n",
            "Epoch: 12, Loss: 0.09382869520811264\n",
            "Epoch: 12, Loss: 0.09380402527122052\n",
            "Epoch: 12, Loss: 0.09373603211123457\n",
            "Epoch: 12, Loss: 0.09343999950707116\n",
            "Epoch: 12, Loss: 0.09316962685991537\n",
            "Epoch: 12, Loss: 0.09301014182522528\n",
            "Epoch: 12, Loss: 0.09351863606122261\n",
            "Epoch: 12, Loss: 0.09325583287378929\n",
            "Epoch: 12, Loss: 0.09312561991427958\n",
            "Epoch: 12, Loss: 0.09289253923624496\n",
            "Epoch: 12, Loss: 0.09263998558552763\n",
            "Epoch: 12, Loss: 0.09249844882248148\n",
            "Epoch: 12, Loss: 0.09242056603082567\n",
            "Epoch: 12, Loss: 0.09250058616878984\n",
            "Epoch: 12, Loss: 0.09231545843531268\n",
            "Epoch: 12, Loss: 0.09246218042618067\n",
            "Epoch: 12, Loss: 0.09226793473937646\n",
            "Epoch: 12, Loss: 0.09277679947917443\n",
            "Epoch: 12, Loss: 0.09348470093931592\n",
            "Epoch: 12, Loss: 0.09407528859097511\n",
            "Epoch: 12, Loss: 0.09402374927406246\n",
            "Epoch: 12, Loss: 0.09382223020098018\n",
            "Epoch: 12, Loss: 0.09410931895834336\n",
            "Epoch: 12, Loss: 0.09403712481817868\n",
            "Epoch: 12, Loss: 0.09398952495825828\n",
            "Epoch: 12, Loss: 0.09377995338382236\n",
            "Epoch: 12, Loss: 0.09366725559167394\n",
            "Epoch: 12, Loss: 0.09385900813088353\n",
            "Epoch: 12, Loss: 0.09372791867781563\n",
            "Epoch: 12, Loss: 0.09369707278636916\n",
            "Epoch: 12, Loss: 0.09357997345501538\n",
            "Epoch: 12, Loss: 0.09367767009042346\n",
            "Epoch: 12, Loss: 0.0941002831121865\n",
            "Epoch: 12, Loss: 0.09397420582990311\n",
            "Epoch: 12, Loss: 0.09432592526048658\n",
            "Epoch: 12, Loss: 0.09518375749186954\n",
            "Epoch: 12, Loss: 0.09492549814771543\n",
            "Epoch: 12, Loss: 0.09542070673456497\n",
            "Epoch: 12, Loss: 0.09568059241083862\n",
            "Epoch: 12, Loss: 0.09550843977922341\n",
            "Epoch: 12, Loss: 0.09561929360722594\n",
            "Epoch: 12, Loss: 0.09616970038186087\n",
            "Epoch: 12, Loss: 0.09624196250920095\n",
            "Epoch: 12, Loss: 0.09609923242551079\n",
            "Epoch: 12, Loss: 0.09631191443795195\n",
            "Epoch: 12, Loss: 0.09650436992059959\n",
            "Epoch: 12, Loss: 0.09640458900487159\n",
            "Epoch: 12, Loss: 0.09653742624895374\n",
            "Epoch: 12, Loss: 0.09640741912013989\n",
            "Epoch: 12, Loss: 0.09669271583217337\n",
            "Epoch: 12, Loss: 0.09698873017619158\n",
            "Epoch: 12, Loss: 0.09677340115381247\n",
            "Epoch: 12, Loss: 0.09684366943571975\n",
            "Epoch: 12, Loss: 0.09675574169248834\n",
            "Epoch: 12, Loss: 0.09723747177327524\n",
            "Epoch: 12, Loss: 0.09701003639687163\n",
            "Epoch: 12, Loss: 0.09700879038833855\n",
            "Epoch: 12, Loss: 0.09722590102461448\n",
            "Epoch: 12, Loss: 0.09713735229096714\n",
            "Epoch: 12, Loss: 0.09708012813455699\n",
            "Epoch: 12, Loss: 0.09701223695333883\n",
            "Epoch: 12, Loss: 0.09706104433365514\n",
            "Epoch: 12, Loss: 0.09679861296152929\n",
            "Epoch: 12, Loss: 0.09673209677905191\n",
            "Epoch: 12, Loss: 0.09700372546263362\n",
            "Epoch: 12, Loss: 0.09680568803144846\n",
            "Epoch: 12, Loss: 0.09700999674669089\n",
            "Epoch: 12, Loss: 0.09701745943755083\n",
            "Epoch: 12, Loss: 0.09749687251162563\n",
            "Epoch: 12, Loss: 0.09777935849236591\n",
            "Epoch: 12, Loss: 0.09769942228844193\n",
            "Epoch: 12, Loss: 0.0975248767327602\n",
            "Epoch: 12, Loss: 0.09739838623396904\n",
            "Epoch: 12, Loss: 0.09771906338779435\n",
            "Epoch: 12, Loss: 0.09752265456801569\n",
            "Epoch: 12, Loss: 0.09734192413665103\n",
            "Epoch: 12, Loss: 0.09732706849502415\n",
            "Epoch: 12, Loss: 0.09743423606451164\n",
            "Epoch: 12, Loss: 0.0973297698490716\n",
            "Epoch: 12, Loss: 0.09775422179761033\n",
            "Epoch: 12, Loss: 0.09754134731630375\n",
            "Epoch: 12, Loss: 0.09769514615220425\n",
            "Epoch: 12, Loss: 0.09799131172768176\n",
            "Epoch: 12, Loss: 0.09823295732468858\n",
            "Epoch: 12, Loss: 0.09837697005945525\n",
            "Epoch: 12, Loss: 0.09822530324362178\n",
            "Epoch: 12, Loss: 0.09806879459086004\n",
            "Epoch: 12, Loss: 0.09820696048985195\n",
            "Epoch: 12, Loss: 0.09804136157136784\n",
            "Epoch: 12, Loss: 0.09789333723586154\n",
            "Epoch: 12, Loss: 0.09773080046426735\n",
            "Epoch: 12, Loss: 0.09797007005201072\n",
            "Epoch: 12, Loss: 0.09786199436250864\n",
            "Epoch: 12, Loss: 0.0979005685574151\n",
            "Epoch: 12, Loss: 0.09796048000951608\n",
            "Epoch: 12, Loss: 0.09780491220249617\n",
            "Epoch: 12, Loss: 0.09760551828525427\n",
            "Epoch: 12, Loss: 0.09742945937745312\n",
            "Epoch: 12, Loss: 0.09734889259930493\n",
            "Epoch: 12, Loss: 0.09731658503511234\n",
            "Epoch: 12, Loss: 0.09749807959564245\n",
            "Epoch: 12, Loss: 0.09759777673661553\n",
            "Epoch: 12, Loss: 0.09753662003958039\n",
            "Epoch: 12, Loss: 0.09746015615625463\n",
            "Epoch: 12, Loss: 0.09747769670536766\n",
            "Epoch: 12, Loss: 0.09727318807374782\n",
            "Epoch: 12, Loss: 0.09759585889061138\n",
            "Epoch: 12, Loss: 0.0975997070685874\n",
            "Epoch: 12, Loss: 0.09756940818250485\n",
            "Epoch: 12, Loss: 0.09734511639301975\n",
            "Epoch: 12, Loss: 0.09741624176283092\n",
            "Epoch: 12, Loss: 0.0974075460107997\n",
            "Epoch: 12, Loss: 0.09733332974395452\n",
            "Epoch: 12, Loss: 0.09738838610470976\n",
            "Epoch: 12, Loss: 0.09735543682841183\n",
            "Epoch: 12, Loss: 0.09712238143188785\n",
            "Epoch: 12, Loss: 0.09709749177511152\n",
            "Epoch: 12, Loss: 0.0971793159093689\n",
            "Epoch: 12, Loss: 0.09697212164469979\n",
            "Epoch: 12, Loss: 0.09685614785645157\n",
            "Epoch: 12, Loss: 0.09676481858174552\n",
            "Epoch: 12, Loss: 0.0968622861856326\n",
            "Epoch: 12, Loss: 0.09671984690128278\n",
            "Epoch: 12, Loss: 0.09664205582996849\n",
            "Epoch: 12, Loss: 0.09669781543866351\n",
            "Epoch: 12, Loss: 0.09655052894643815\n",
            "Epoch: 12, Loss: 0.09673040297513952\n",
            "Epoch: 12, Loss: 0.09655619959127815\n",
            "Epoch: 12, Loss: 0.09648113840311984\n",
            "Epoch: 12, Loss: 0.09627174541081597\n",
            "Epoch: 12, Loss: 0.0962490956287677\n",
            "Epoch: 12, Loss: 0.09621865015241851\n",
            "Epoch: 12, Loss: 0.09611940084895701\n",
            "Epoch: 12, Loss: 0.0959178248019934\n",
            "Epoch: 12, Loss: 0.09575869473572596\n",
            "Epoch: 12, Loss: 0.09596057376116872\n",
            "Epoch: 12, Loss: 0.09577022634705694\n",
            "Epoch: 12, Loss: 0.09569478955378301\n",
            "Epoch: 12, Loss: 0.09621299124658464\n",
            "Epoch: 12, Loss: 0.09628721384021142\n",
            "Epoch: 12, Loss: 0.09627585127870077\n",
            "Epoch: 12, Loss: 0.09677891536302405\n",
            "Epoch: 12, Loss: 0.09663775125320287\n",
            "Epoch: 12, Loss: 0.09682252826300924\n",
            "Epoch: 12, Loss: 0.09669588768087765\n",
            "Epoch: 12, Loss: 0.09663152579926479\n",
            "Epoch: 12, Loss: 0.09656892359841275\n",
            "Epoch: 12, Loss: 0.09670969957668578\n",
            "Epoch: 12, Loss: 0.09654560010220274\n",
            "Epoch: 12, Loss: 0.09638948006295533\n",
            "Epoch: 12, Loss: 0.09636786734585903\n",
            "Epoch: 12, Loss: 0.09631216402501902\n",
            "Epoch: 12, Loss: 0.09616478775815036\n",
            "Epoch: 12, Loss: 0.0960041267930397\n",
            "Epoch: 12, Loss: 0.09584412199883968\n",
            "Epoch: 12, Loss: 0.09573734428844663\n",
            "Epoch: 12, Loss: 0.0956964319426933\n",
            "Epoch: 12, Loss: 0.09568381188947657\n",
            "Epoch: 12, Loss: 0.09577278363686012\n",
            "Epoch: 12, Loss: 0.09576035978653553\n",
            "Epoch: 12, Loss: 0.09575555999203672\n",
            "Epoch: 12, Loss: 0.09585440833315388\n",
            "Epoch: 12, Loss: 0.09568003205788525\n",
            "Epoch: 12, Loss: 0.09575580468879559\n",
            "Epoch: 12, Loss: 0.0955892169094655\n",
            "Epoch: 12, Loss: 0.095453461525636\n",
            "Epoch: 12, Loss: 0.09540869484153437\n",
            "Epoch: 12, Loss: 0.09522102118977013\n",
            "Epoch: 12, Loss: 0.09518899904037173\n",
            "Epoch: 12, Loss: 0.09516329931923084\n",
            "Epoch: 12, Loss: 0.09497898927127774\n",
            "Epoch: 12, Loss: 0.09582879833786427\n",
            "Epoch: 12, Loss: 0.09597434232805015\n",
            "Epoch: 12, Loss: 0.09625120005787798\n",
            "Epoch: 12, Loss: 0.09608025630465249\n",
            "Epoch: 12, Loss: 0.09594598828545331\n",
            "Epoch: 12, Loss: 0.09602560560449273\n",
            "Epoch: 12, Loss: 0.09584707511369318\n",
            "Epoch: 12, Loss: 0.09572429274064782\n",
            "Epoch: 12, Loss: 0.09561483128725187\n",
            "Epoch: 12, Loss: 0.09567636389632804\n",
            "Epoch: 12, Loss: 0.095588424456713\n",
            "Epoch: 12, Loss: 0.09586530027520837\n",
            "Epoch: 12, Loss: 0.09581331977749179\n",
            "Epoch: 12, Loss: 0.09572788577086182\n",
            "Epoch: 12, Loss: 0.09567839518796989\n",
            "Epoch: 12, Loss: 0.09551978385678195\n",
            "Epoch: 12, Loss: 0.09542841705469748\n",
            "Epoch: 12, Loss: 0.09533549539411246\n",
            "Epoch: 12, Loss: 0.0952834620358462\n",
            "Epoch: 12, Loss: 0.09514953796366218\n",
            "Epoch: 12, Loss: 0.09510072108389715\n",
            "Epoch: 12, Loss: 0.09496843947952192\n",
            "Epoch: 12, Loss: 0.09482575940038962\n",
            "Epoch: 12, Loss: 0.09487286913943918\n",
            "Epoch: 12, Loss: 0.09516251551676072\n",
            "Epoch: 12, Loss: 0.09502466813323383\n",
            "Epoch: 12, Loss: 0.09521127152393054\n",
            "Epoch: 12, Loss: 0.09530252756430362\n",
            "Epoch: 12, Loss: 0.09525990781063835\n",
            "Epoch: 12, Loss: 0.0951007523897284\n",
            "Epoch: 12, Loss: 0.09506622301530541\n",
            "Epoch: 12, Loss: 0.09522779380004105\n",
            "Epoch: 12, Loss: 0.09508606790341745\n",
            "Epoch: 12, Loss: 0.0949364985502565\n",
            "Epoch: 12, Loss: 0.09480186317637256\n",
            "Epoch: 12, Loss: 0.09485762470327241\n",
            "Epoch: 12, Loss: 0.09496796122355172\n",
            "Epoch: 12, Loss: 0.09515406337999005\n",
            "Epoch: 12, Loss: 0.09501649316552342\n",
            "Epoch: 12, Loss: 0.09491254605899153\n",
            "Epoch: 12, Loss: 0.09483291308312275\n",
            "Epoch: 12, Loss: 0.09482201525438992\n",
            "Epoch: 12, Loss: 0.09501647502410146\n",
            "Epoch: 12, Loss: 0.09508507940730061\n",
            "Epoch: 12, Loss: 0.0949820950514667\n",
            "Epoch: 12, Loss: 0.09497476375513753\n",
            "Epoch: 12, Loss: 0.0950057039516099\n",
            "Epoch: 12, Loss: 0.0949361071042821\n",
            "Epoch: 12, Loss: 0.09500023442134262\n",
            "Epoch: 12, Loss: 0.09489866729431642\n",
            "Epoch: 12, Loss: 0.09519798425490043\n",
            "Epoch: 12, Loss: 0.09536682517743608\n",
            "Epoch: 12, Loss: 0.09534369429410805\n",
            "Epoch: 12, Loss: 0.09527524133203644\n",
            "Epoch: 12, Loss: 0.09557352847099422\n",
            "Epoch: 12, Loss: 0.09544246720932645\n",
            "Epoch: 12, Loss: 0.09535432142740864\n",
            "Epoch: 12, Loss: 0.09518381066195856\n",
            "Epoch: 12, Loss: 0.09512698035321984\n",
            "Epoch: 12, Loss: 0.09508581775916766\n",
            "Epoch: 12, Loss: 0.09497968790674349\n",
            "Epoch: 12, Loss: 0.09501958453254393\n",
            "Epoch: 12, Loss: 0.09517122624652163\n",
            "Epoch: 12, Loss: 0.09511018352745806\n",
            "Epoch: 12, Loss: 0.09502686690827904\n",
            "Epoch: 12, Loss: 0.09506016471774481\n",
            "Epoch: 12, Loss: 0.09514009403819973\n",
            "Epoch: 12, Loss: 0.09524128349903462\n",
            "Epoch: 12, Loss: 0.09512233522075873\n",
            "Epoch: 12, Loss: 0.09515036142032572\n",
            "Epoch: 12, Loss: 0.09517288305065184\n",
            "Epoch: 12, Loss: 0.09503090340309343\n",
            "Epoch: 12, Loss: 0.09500813255271384\n",
            "Epoch: 12, Loss: 0.09517699146554584\n",
            "Epoch: 12, Loss: 0.09507769730806125\n",
            "Epoch: 12, Loss: 0.09494468567634895\n",
            "Epoch: 12, Loss: 0.09497255470011044\n",
            "Epoch: 12, Loss: 0.0948980605416352\n",
            "Epoch: 12, Loss: 0.09514707488552579\n",
            "Epoch: 12, Loss: 0.09507190225656423\n",
            "Epoch: 12, Loss: 0.09516676813644126\n",
            "Epoch: 12, Loss: 0.09532265995557491\n",
            "Epoch: 12, Loss: 0.0953975087554937\n",
            "Epoch: 12, Loss: 0.09543421977312766\n",
            "Epoch: 12, Loss: 0.09544412531792673\n",
            "Epoch: 12, Loss: 0.09552240381416217\n",
            "Epoch: 12, Loss: 0.09544439455944366\n",
            "Epoch: 12, Loss: 0.09530838721661598\n",
            "Epoch: 12, Loss: 0.09544080678304588\n",
            "Epoch: 12, Loss: 0.0954278328674613\n",
            "Epoch: 12, Loss: 0.0953994321214152\n",
            "Epoch: 12, Loss: 0.09528514058509255\n",
            "Epoch: 12, Loss: 0.09523227357867119\n",
            "Epoch: 12, Loss: 0.09524714200663457\n",
            "Epoch: 12, Loss: 0.09516186198567624\n",
            "Epoch: 12, Loss: 0.09525719235635871\n",
            "Epoch: 12, Loss: 0.09541699972452365\n",
            "Epoch: 12, Loss: 0.09560040583688162\n",
            "Epoch: 12, Loss: 0.09548899367113005\n",
            "Epoch: 12, Loss: 0.09540119838517179\n",
            "Epoch: 12, Loss: 0.09530246134617947\n",
            "Epoch: 12, Loss: 0.0955836588708822\n",
            "Epoch: 12, Loss: 0.0957177916797221\n",
            "Epoch: 12, Loss: 0.09564994747104409\n",
            "Epoch: 12, Loss: 0.0961336965887077\n",
            "Epoch: 12, Loss: 0.09633647067609445\n",
            "Epoch: 12, Loss: 0.09647464110285685\n",
            "Epoch: 12, Loss: 0.0965484240673789\n",
            "Epoch: 12, Loss: 0.09663688307960651\n",
            "Epoch: 12, Loss: 0.09654873043444812\n",
            "Epoch: 12, Loss: 0.09657224166634562\n",
            "Epoch: 12, Loss: 0.096485551066207\n",
            "Epoch: 12, Loss: 0.09636249772358871\n",
            "Epoch: 12, Loss: 0.09635088468811154\n",
            "Epoch: 12, Loss: 0.09625105393306738\n",
            "Epoch: 12, Loss: 0.09664743557256997\n",
            "Epoch: 12, Loss: 0.09687456915574805\n",
            "Epoch: 12, Loss: 0.09683733570319068\n",
            "Epoch: 12, Loss: 0.09675245630113702\n",
            "Epoch: 12, Loss: 0.09679119452025134\n",
            "Epoch: 12, Loss: 0.09684496504495611\n",
            "Epoch: 12, Loss: 0.09669899769666983\n",
            "Epoch: 12, Loss: 0.09675791647564295\n",
            "Epoch: 12, Loss: 0.0967048044907658\n",
            "Epoch: 12, Loss: 0.09656953663054285\n",
            "Epoch: 12, Loss: 0.09654679836501953\n",
            "Epoch: 12, Loss: 0.09652319100804653\n",
            "Epoch: 12, Loss: 0.09673658555248087\n",
            "Epoch: 12, Loss: 0.09686400105630787\n",
            "Epoch: 12, Loss: 0.09693719525044069\n",
            "Epoch: 12, Loss: 0.09691212556878571\n",
            "Epoch: 12, Loss: 0.09696086405538419\n",
            "Epoch: 12, Loss: 0.09690731010010645\n",
            "Epoch: 12, Loss: 0.09732306402367659\n",
            "Epoch: 12, Loss: 0.0973141638024904\n",
            "Epoch: 12, Loss: 0.09739545301345433\n",
            "Epoch: 12, Loss: 0.09766449251047456\n",
            "Epoch: 12, Loss: 0.09769653854180121\n",
            "Epoch: 12, Loss: 0.09805512605234981\n",
            "Epoch: 12, Loss: 0.09810982853987343\n",
            "Epoch: 12, Loss: 0.09799959778791999\n",
            "Epoch: 12, Loss: 0.09819029511736226\n",
            "Epoch: 12, Loss: 0.09835866917871716\n",
            "Epoch: 12, Loss: 0.09831177741445664\n",
            "Epoch: 12, Loss: 0.0982337435785581\n",
            "Epoch: 12, Loss: 0.09825697976946082\n",
            "Epoch: 12, Loss: 0.09817565374082596\n",
            "Epoch: 12, Loss: 0.09839432386336273\n",
            "Epoch: 12, Loss: 0.09827630128245801\n",
            "Epoch: 12, Loss: 0.09832001861321202\n",
            "Epoch: 12, Loss: 0.0981951902707129\n",
            "Epoch: 12, Loss: 0.0982072612944107\n",
            "Epoch: 12, Loss: 0.09810204018641337\n",
            "Epoch: 12, Loss: 0.09825453432353813\n",
            "Epoch: 12, Loss: 0.0981952759418821\n",
            "Epoch: 12, Loss: 0.09810206975751054\n",
            "Epoch: 12, Loss: 0.09818805444611874\n",
            "Epoch: 12, Loss: 0.09818753106320775\n",
            "Epoch: 12, Loss: 0.09816366032712528\n",
            "Epoch: 12, Loss: 0.09821448397537641\n",
            "Epoch: 12, Loss: 0.09821962999039957\n",
            "Epoch: 12, Loss: 0.0981157908100653\n",
            "Epoch: 12, Loss: 0.09814566462255213\n",
            "Epoch: 12, Loss: 0.09807395538754338\n",
            "Epoch: 12, Loss: 0.09813851511027277\n",
            "Epoch: 12, Loss: 0.09818378132971749\n",
            "Epoch: 12, Loss: 0.09834827076263943\n",
            "Epoch: 12, Loss: 0.09829068826496457\n",
            "Epoch: 12, Loss: 0.09825648507854391\n",
            "Epoch: 12, Loss: 0.0983529468914329\n",
            "Epoch: 12, Loss: 0.09829213234095856\n",
            "Epoch: 12, Loss: 0.09819741271896644\n",
            "Epoch: 12, Loss: 0.09828074830315578\n",
            "Epoch: 12, Loss: 0.09843578841537237\n",
            "Epoch: 12, Loss: 0.098602236410716\n",
            "Epoch: 12, Loss: 0.09858801181278112\n",
            "Epoch: 12, Loss: 0.09857454142462059\n",
            "Epoch: 12, Loss: 0.09848649013751973\n",
            "Epoch: 12, Loss: 0.0983886934861186\n",
            "Epoch: 12, Loss: 0.09856145692437226\n",
            "Epoch: 12, Loss: 0.09850185849450387\n",
            "Epoch: 12, Loss: 0.09857811637981949\n",
            "Epoch: 12, Loss: 0.09885272693200395\n",
            "Epoch: 12, Loss: 0.09875716289402697\n",
            "Epoch: 12, Loss: 0.09906040529615052\n",
            "Epoch: 12, Loss: 0.09905308414121952\n",
            "Epoch: 12, Loss: 0.09898795089231903\n",
            "Epoch: 12, Loss: 0.09886996913701296\n",
            "Epoch: 12, Loss: 0.0987972419054131\n",
            "Epoch: 12, Loss: 0.09879919268661608\n",
            "Epoch: 12, Loss: 0.09872247786855912\n",
            "Epoch: 12, Loss: 0.09859669800198885\n",
            "Epoch: 12, Loss: 0.09849489421977066\n",
            "Epoch: 12, Loss: 0.09843861708027679\n",
            "Epoch: 12, Loss: 0.09843871631910418\n",
            "Epoch: 12, Loss: 0.09850905414302208\n",
            "Epoch: 12, Loss: 0.09842777209799093\n",
            "Epoch: 12, Loss: 0.09844534362139659\n",
            "Epoch: 12, Loss: 0.09854519010879673\n",
            "Epoch: 12, Loss: 0.09842868566587452\n",
            "Epoch: 12, Loss: 0.09836024605451964\n",
            "Epoch: 12, Loss: 0.09832767550769343\n",
            "Epoch: 12, Loss: 0.09823775022156787\n",
            "Epoch: 12, Loss: 0.09818736429233815\n",
            "Epoch: 12, Loss: 0.09809739637421444\n",
            "Epoch: 12, Loss: 0.09807184236081631\n",
            "Epoch: 12, Loss: 0.09818314871464864\n",
            "Epoch: 12, Loss: 0.09811568388090736\n",
            "Epoch: 12, Loss: 0.09813534535157184\n",
            "Epoch: 12, Loss: 0.09815112482361868\n",
            "Epoch: 12, Loss: 0.09802752433997491\n",
            "Epoch: 12, Loss: 0.09791969331360645\n",
            "Epoch: 12, Loss: 0.09781254195827004\n",
            "Epoch: 12, Loss: 0.09772252075346116\n",
            "Epoch: 12, Loss: 0.0978089787147089\n",
            "Epoch: 12, Loss: 0.09769129436574821\n",
            "Epoch: 12, Loss: 0.09765662643974814\n",
            "Epoch: 12, Loss: 0.0975921082203186\n",
            "Epoch: 12, Loss: 0.0978435142174252\n",
            "Epoch: 12, Loss: 0.09779942700925287\n",
            "Epoch: 12, Loss: 0.09773270402885308\n",
            "Epoch: 12, Loss: 0.09795306431043777\n",
            "Epoch: 12, Loss: 0.09787708063380522\n",
            "Epoch: 12, Loss: 0.09782454775577341\n",
            "Epoch: 12, Loss: 0.097900357738016\n",
            "Epoch: 12, Loss: 0.09785966289145775\n",
            "Epoch: 12, Loss: 0.09787940236281022\n",
            "Epoch: 12, Loss: 0.0978812897517531\n",
            "Epoch: 12, Loss: 0.0978564667803071\n",
            "Epoch: 12, Loss: 0.09786380454487606\n",
            "Epoch: 12, Loss: 0.0978711164867795\n",
            "Epoch: 12, Loss: 0.09781351590210008\n",
            "Epoch: 12, Loss: 0.0978238043056703\n",
            "Epoch: 12, Loss: 0.09793190643544833\n",
            "Epoch: 12, Loss: 0.09787586604655006\n",
            "Epoch: 12, Loss: 0.09776398111297444\n",
            "Epoch: 12, Loss: 0.09789457587054172\n",
            "Epoch: 12, Loss: 0.09801817255118978\n",
            "Epoch: 12, Loss: 0.09794753964423486\n",
            "Epoch: 12, Loss: 0.09787914474587753\n",
            "Epoch: 12, Loss: 0.0980226803918213\n",
            "Epoch: 12, Loss: 0.09790926022269639\n",
            "Epoch: 12, Loss: 0.09779445172800154\n",
            "Epoch: 12, Loss: 0.0979658436713566\n",
            "Epoch: 12, Loss: 0.09822627108399595\n",
            "Epoch: 12, Loss: 0.09811868113592545\n",
            "Epoch: 12, Loss: 0.09800221728171651\n",
            "Epoch: 12, Loss: 0.09796984328386055\n",
            "Epoch: 12, Loss: 0.09793979484987046\n",
            "Epoch: 12, Loss: 0.09792027121725971\n",
            "Epoch: 12, Loss: 0.09779981087145005\n",
            "Epoch: 12, Loss: 0.09789229858041361\n",
            "Epoch: 12, Loss: 0.09794257501463025\n",
            "Epoch: 12, Loss: 0.09783220829719559\n",
            "Epoch: 12, Loss: 0.09785689985136853\n",
            "Epoch: 12, Loss: 0.09802035856307016\n",
            "Epoch: 12, Loss: 0.09806038213678041\n",
            "Epoch: 12, Loss: 0.09805459676938308\n",
            "Epoch: 12, Loss: 0.0981499734649461\n",
            "Epoch: 12, Loss: 0.09819897252322292\n",
            "Epoch: 12, Loss: 0.0981757789601708\n",
            "Epoch: 12, Loss: 0.09806482540247609\n",
            "Epoch: 12, Loss: 0.09801204732543572\n",
            "Epoch: 12, Loss: 0.0978861398526005\n",
            "Epoch: 12, Loss: 0.09782358449909774\n",
            "Epoch: 12, Loss: 0.09774780351372443\n",
            "Epoch: 12, Loss: 0.09770570905012672\n",
            "Epoch: 12, Loss: 0.09760764457015982\n",
            "Epoch: 12, Loss: 0.09764416084573087\n",
            "Epoch: 12, Loss: 0.09764125684066967\n",
            "Epoch: 12, Loss: 0.09769425106975263\n",
            "Epoch: 12, Loss: 0.09785443689947224\n",
            "Epoch: 12, Loss: 0.09797171765979565\n",
            "Epoch: 12, Loss: 0.0979058273419224\n",
            "Epoch: 12, Loss: 0.09796744054722145\n",
            "Epoch: 12, Loss: 0.09807335878715964\n",
            "Epoch: 12, Loss: 0.09799424347283503\n",
            "Epoch: 12, Loss: 0.09795106398848757\n",
            "Epoch: 12, Loss: 0.09797279026665508\n",
            "Epoch: 12, Loss: 0.09790100549919742\n",
            "Epoch: 12, Loss: 0.09790619461965121\n",
            "Epoch: 12, Loss: 0.09797654959842014\n",
            "Epoch: 12, Loss: 0.09790793121399038\n",
            "Epoch: 12, Loss: 0.09789402238821902\n",
            "Epoch: 12, Loss: 0.09791906976961004\n",
            "Epoch: 12, Loss: 0.09785563769412899\n",
            "Epoch: 12, Loss: 0.09781322007125551\n",
            "Epoch: 12, Loss: 0.09775747418534692\n",
            "Epoch: 12, Loss: 0.0977987269820595\n",
            "Epoch: 12, Loss: 0.09796708079454629\n",
            "Epoch: 12, Loss: 0.09792994143757618\n",
            "Epoch: 12, Loss: 0.09782824487316336\n",
            "Epoch: 12, Loss: 0.09772883194638916\n",
            "Epoch: 12, Loss: 0.09768818277090588\n",
            "Epoch: 12, Loss: 0.09760763074943032\n",
            "Epoch: 12, Loss: 0.0975213386043607\n",
            "Epoch: 12, Loss: 0.09748499461743522\n",
            "Epoch: 12, Loss: 0.09756011894601925\n",
            "Epoch: 12, Loss: 0.09759687097618977\n",
            "Epoch: 12, Loss: 0.09754018493234794\n",
            "Epoch: 12, Loss: 0.0976763877477695\n",
            "Epoch: 12, Loss: 0.09769700874993763\n",
            "Epoch: 12, Loss: 0.09761142687975807\n",
            "Epoch: 12, Loss: 0.0975420753662752\n",
            "Epoch: 12, Loss: 0.09744018036379386\n",
            "Epoch: 12, Loss: 0.09747625640353565\n",
            "Epoch: 12, Loss: 0.09754621501923551\n",
            "Epoch: 12, Loss: 0.09748163612188872\n",
            "Epoch: 12, Loss: 0.0974870953904955\n",
            "Epoch: 12, Loss: 0.09740572389455099\n",
            "Epoch: 12, Loss: 0.09728976627298462\n",
            "Epoch: 12, Loss: 0.09731040304944134\n",
            "Epoch: 12, Loss: 0.09725452808624241\n",
            "Epoch: 12, Loss: 0.09759693178135195\n",
            "Epoch: 12, Loss: 0.09749917947144951\n",
            "Epoch: 12, Loss: 0.09745818648045346\n",
            "Epoch: 12, Loss: 0.09745046130168096\n",
            "Epoch: 12, Loss: 0.09742835450370073\n",
            "Epoch: 12, Loss: 0.09741703565534833\n",
            "Epoch: 12, Loss: 0.09781946421114078\n",
            "Epoch: 12, Loss: 0.09807806191338622\n",
            "Epoch: 12, Loss: 0.09808131687603361\n",
            "Epoch: 12, Loss: 0.09823783244023182\n",
            "Epoch: 12, Loss: 0.09826982173708178\n",
            "Epoch: 12, Loss: 0.09818196428229206\n",
            "Epoch: 12, Loss: 0.0982235445613413\n",
            "Epoch: 12, Loss: 0.09825271436020463\n",
            "Epoch: 12, Loss: 0.09835884846335657\n",
            "Epoch: 12, Loss: 0.09830730731766193\n",
            "Epoch: 12, Loss: 0.09830164815395803\n",
            "Epoch: 12, Loss: 0.09822382176261577\n",
            "Epoch: 13, Loss: 0.09828941313262035\n",
            "Epoch: 13, Loss: 0.0982666511554271\n",
            "Epoch: 13, Loss: 0.09825594505401933\n",
            "Epoch: 13, Loss: 0.09821506153138085\n",
            "Epoch: 13, Loss: 0.09817978112545371\n",
            "Epoch: 13, Loss: 0.09811718016862869\n",
            "Epoch: 13, Loss: 0.09842467602668153\n",
            "Epoch: 13, Loss: 0.09832463075843038\n",
            "Epoch: 13, Loss: 0.09834705400557343\n",
            "Epoch: 13, Loss: 0.09846104739817103\n",
            "Epoch: 13, Loss: 0.09840808675858141\n",
            "Epoch: 13, Loss: 0.09842367632131582\n",
            "Epoch: 13, Loss: 0.09840613132658994\n",
            "Epoch: 13, Loss: 0.09836808470868735\n",
            "Epoch: 13, Loss: 0.09829077956592723\n",
            "Epoch: 13, Loss: 0.09834033771789163\n",
            "Epoch: 13, Loss: 0.09834141539729134\n",
            "Epoch: 13, Loss: 0.0983252043928951\n",
            "Epoch: 13, Loss: 0.0982772247603026\n",
            "Epoch: 13, Loss: 0.0981826539734318\n",
            "Epoch: 13, Loss: 0.0981005727200958\n",
            "Epoch: 13, Loss: 0.09819455558563865\n",
            "Epoch: 13, Loss: 0.09814473537971144\n",
            "Epoch: 13, Loss: 0.0981363932123736\n",
            "Epoch: 13, Loss: 0.09815790950374902\n",
            "Epoch: 13, Loss: 0.09834398936231316\n",
            "Epoch: 13, Loss: 0.09828511465971712\n",
            "Epoch: 13, Loss: 0.09827185025507654\n",
            "Epoch: 13, Loss: 0.09823531820754602\n",
            "Epoch: 13, Loss: 0.09822373630552383\n",
            "Epoch: 13, Loss: 0.09825706127045852\n",
            "Epoch: 13, Loss: 0.0981596919367003\n",
            "Epoch: 13, Loss: 0.09819009940317072\n",
            "Epoch: 13, Loss: 0.09823132457905541\n",
            "Epoch: 13, Loss: 0.09823854992592496\n",
            "Epoch: 13, Loss: 0.09817369294541826\n",
            "Epoch: 13, Loss: 0.09822096228508577\n",
            "Epoch: 13, Loss: 0.09812205474278549\n",
            "Epoch: 13, Loss: 0.09840026476514616\n",
            "Epoch: 13, Loss: 0.09847154642779317\n",
            "Epoch: 13, Loss: 0.09845797503468912\n",
            "Epoch: 13, Loss: 0.09869913291638192\n",
            "Epoch: 13, Loss: 0.09865928133780306\n",
            "Epoch: 13, Loss: 0.0986429632260277\n",
            "Epoch: 13, Loss: 0.09861721077251463\n",
            "Epoch: 13, Loss: 0.09854085670541161\n",
            "Epoch: 13, Loss: 0.09850731406661943\n",
            "Epoch: 13, Loss: 0.09845091912401728\n",
            "Epoch: 13, Loss: 0.09847794347650021\n",
            "Epoch: 13, Loss: 0.09853391386926748\n",
            "Epoch: 13, Loss: 0.09852687000226573\n",
            "Epoch: 13, Loss: 0.0984606811959895\n",
            "Epoch: 13, Loss: 0.09841488822848497\n",
            "Epoch: 13, Loss: 0.09845027286541519\n",
            "Epoch: 13, Loss: 0.09835758938575374\n",
            "Epoch: 13, Loss: 0.0983111118666632\n",
            "Epoch: 13, Loss: 0.09833956969162634\n",
            "Epoch: 13, Loss: 0.09824756509624422\n",
            "Epoch: 13, Loss: 0.09836279489897307\n",
            "Epoch: 13, Loss: 0.09829749046402349\n",
            "Epoch: 13, Loss: 0.09818713692837745\n",
            "Epoch: 13, Loss: 0.09815105395689519\n",
            "Epoch: 13, Loss: 0.09812537977229473\n",
            "Epoch: 13, Loss: 0.09805136741288711\n",
            "Epoch: 13, Loss: 0.09804366841426267\n",
            "Epoch: 13, Loss: 0.0980221701380665\n",
            "Epoch: 13, Loss: 0.09796966914826888\n",
            "Epoch: 13, Loss: 0.09800846021567636\n",
            "Epoch: 13, Loss: 0.09799235943348074\n",
            "Epoch: 13, Loss: 0.09796581627798874\n",
            "Epoch: 13, Loss: 0.09790875082879227\n",
            "Epoch: 13, Loss: 0.0978918135121456\n",
            "Epoch: 13, Loss: 0.09805046029508724\n",
            "Epoch: 13, Loss: 0.09798081909582698\n",
            "Epoch: 13, Loss: 0.09798361642868665\n",
            "Epoch: 13, Loss: 0.09812840025835086\n",
            "Epoch: 13, Loss: 0.09808719420276486\n",
            "Epoch: 13, Loss: 0.09808414232061613\n",
            "Epoch: 13, Loss: 0.09799593628809271\n",
            "Epoch: 13, Loss: 0.09795015227220295\n",
            "Epoch: 13, Loss: 0.09786879959940341\n",
            "Epoch: 13, Loss: 0.09795680687562304\n",
            "Epoch: 13, Loss: 0.09789101891165783\n",
            "Epoch: 13, Loss: 0.09789124854483296\n",
            "Epoch: 13, Loss: 0.09783433626686258\n",
            "Epoch: 13, Loss: 0.09776976054120157\n",
            "Epoch: 13, Loss: 0.09769016181218457\n",
            "Epoch: 13, Loss: 0.09760851849930297\n",
            "Epoch: 13, Loss: 0.09750457984918191\n",
            "Epoch: 13, Loss: 0.09746977639141056\n",
            "Epoch: 13, Loss: 0.09742809386277423\n",
            "Epoch: 13, Loss: 0.09733452195582967\n",
            "Epoch: 13, Loss: 0.0973731913172773\n",
            "Epoch: 13, Loss: 0.09731655680472413\n",
            "Epoch: 13, Loss: 0.09737161340822753\n",
            "Epoch: 13, Loss: 0.09742345074021973\n",
            "Epoch: 13, Loss: 0.09732256038273357\n",
            "Epoch: 13, Loss: 0.0975210666000335\n",
            "Epoch: 13, Loss: 0.09753581149361934\n",
            "Epoch: 13, Loss: 0.09746823844430196\n",
            "Epoch: 13, Loss: 0.09741987174298795\n",
            "Epoch: 13, Loss: 0.09739974704339291\n",
            "Epoch: 13, Loss: 0.09743728014919381\n",
            "Epoch: 13, Loss: 0.09737089733565836\n",
            "Epoch: 13, Loss: 0.09777094939305724\n",
            "Epoch: 13, Loss: 0.09767959144192974\n",
            "Epoch: 13, Loss: 0.09775344472424587\n",
            "Epoch: 13, Loss: 0.097764536644217\n",
            "Epoch: 13, Loss: 0.09767493820727273\n",
            "Epoch: 13, Loss: 0.09773592219266189\n",
            "Epoch: 13, Loss: 0.09778923941995168\n",
            "Epoch: 13, Loss: 0.09771694971552698\n",
            "Epoch: 13, Loss: 0.09785842211427968\n",
            "Epoch: 13, Loss: 0.09786321349383797\n",
            "Epoch: 13, Loss: 0.09778437047673508\n",
            "Epoch: 13, Loss: 0.09776331592384385\n",
            "Epoch: 13, Loss: 0.09776437556261282\n",
            "Epoch: 13, Loss: 0.09774732186769446\n",
            "Epoch: 13, Loss: 0.09769209376541478\n",
            "Epoch: 13, Loss: 0.09772897096032776\n",
            "Epoch: 13, Loss: 0.09765599946288242\n",
            "Epoch: 13, Loss: 0.09757449887734138\n",
            "Epoch: 13, Loss: 0.09749461699956359\n",
            "Epoch: 13, Loss: 0.0974465198465366\n",
            "Epoch: 13, Loss: 0.09738490211160272\n",
            "Epoch: 13, Loss: 0.0972922194158322\n",
            "Epoch: 13, Loss: 0.09727261515438754\n",
            "Epoch: 13, Loss: 0.09719332370620508\n",
            "Epoch: 13, Loss: 0.09717174739659683\n",
            "Epoch: 13, Loss: 0.09730432690693099\n",
            "Epoch: 13, Loss: 0.09724138738324321\n",
            "Epoch: 13, Loss: 0.09716111893767666\n",
            "Epoch: 13, Loss: 0.0972061405681033\n",
            "Epoch: 13, Loss: 0.09713245312963902\n",
            "Epoch: 13, Loss: 0.09712065997225768\n",
            "Epoch: 13, Loss: 0.09702757440815823\n",
            "Epoch: 13, Loss: 0.09701228582009397\n",
            "Epoch: 13, Loss: 0.09695973694729416\n",
            "Epoch: 13, Loss: 0.09692481353102367\n",
            "Epoch: 13, Loss: 0.09707018874036127\n",
            "Epoch: 13, Loss: 0.09704449623096674\n",
            "Epoch: 13, Loss: 0.09710067456176916\n",
            "Epoch: 13, Loss: 0.09715836617189484\n",
            "Epoch: 13, Loss: 0.09730737368710998\n",
            "Epoch: 13, Loss: 0.09722826753249704\n",
            "Epoch: 13, Loss: 0.09713196626499071\n",
            "Epoch: 13, Loss: 0.0971694529202914\n",
            "Epoch: 13, Loss: 0.09708921982335948\n",
            "Epoch: 13, Loss: 0.09699250931254359\n",
            "Epoch: 13, Loss: 0.09693448470861456\n",
            "Epoch: 13, Loss: 0.09685149682947262\n",
            "Epoch: 13, Loss: 0.09676344148072812\n",
            "Epoch: 13, Loss: 0.09674247679584486\n",
            "Epoch: 13, Loss: 0.09674026353213076\n",
            "Epoch: 13, Loss: 0.09667655370191233\n",
            "Epoch: 13, Loss: 0.09687516829773371\n",
            "Epoch: 13, Loss: 0.09683998914770742\n",
            "Epoch: 13, Loss: 0.09679286272879294\n",
            "Epoch: 13, Loss: 0.09679688365811306\n",
            "Epoch: 13, Loss: 0.09695563316463855\n",
            "Epoch: 13, Loss: 0.09693369702934776\n",
            "Epoch: 13, Loss: 0.09688575081014217\n",
            "Epoch: 13, Loss: 0.09682392973314832\n",
            "Epoch: 13, Loss: 0.09673422525575814\n",
            "Epoch: 13, Loss: 0.09664471817046498\n",
            "Epoch: 13, Loss: 0.09656744522439466\n",
            "Epoch: 13, Loss: 0.0964784056460534\n",
            "Epoch: 13, Loss: 0.09647456823309002\n",
            "Epoch: 13, Loss: 0.0964192629544031\n",
            "Epoch: 13, Loss: 0.09637328867405309\n",
            "Epoch: 13, Loss: 0.09634049003113135\n",
            "Epoch: 13, Loss: 0.09628997243007555\n",
            "Epoch: 13, Loss: 0.09626172107415205\n",
            "Epoch: 13, Loss: 0.09620646060498969\n",
            "Epoch: 13, Loss: 0.09613724359356902\n",
            "Epoch: 13, Loss: 0.09614538639056688\n",
            "Epoch: 13, Loss: 0.09608681235128355\n",
            "Epoch: 13, Loss: 0.09611227978117919\n",
            "Epoch: 13, Loss: 0.09614990550916135\n",
            "Epoch: 13, Loss: 0.09608680958300055\n",
            "Epoch: 13, Loss: 0.09608521338490342\n",
            "Epoch: 13, Loss: 0.09605217970525112\n",
            "Epoch: 13, Loss: 0.09608991283228514\n",
            "Epoch: 13, Loss: 0.09599746423137161\n",
            "Epoch: 13, Loss: 0.09604119134569905\n",
            "Epoch: 13, Loss: 0.09612946007891428\n",
            "Epoch: 13, Loss: 0.09605210504116889\n",
            "Epoch: 13, Loss: 0.09606097043088647\n",
            "Epoch: 13, Loss: 0.09610252870135508\n",
            "Epoch: 13, Loss: 0.09603055969499619\n",
            "Epoch: 13, Loss: 0.09601405448780873\n",
            "Epoch: 13, Loss: 0.09605503641212362\n",
            "Epoch: 13, Loss: 0.09599088836700106\n",
            "Epoch: 13, Loss: 0.0959006104533385\n",
            "Epoch: 13, Loss: 0.09587490856561699\n",
            "Epoch: 13, Loss: 0.09590101174025555\n",
            "Epoch: 13, Loss: 0.09584297579727435\n",
            "Epoch: 13, Loss: 0.09578732450312118\n",
            "Epoch: 13, Loss: 0.09570121361706008\n",
            "Epoch: 13, Loss: 0.09583025963459156\n",
            "Epoch: 13, Loss: 0.09579462730699993\n",
            "Epoch: 13, Loss: 0.09574716370335092\n",
            "Epoch: 13, Loss: 0.09576308309965706\n",
            "Epoch: 13, Loss: 0.09566837588597173\n",
            "Epoch: 13, Loss: 0.0956377799442489\n",
            "Epoch: 13, Loss: 0.09569725315161955\n",
            "Epoch: 13, Loss: 0.09565858274069214\n",
            "Epoch: 13, Loss: 0.09568956605055266\n",
            "Epoch: 13, Loss: 0.09566278300153169\n",
            "Epoch: 13, Loss: 0.09567428684526784\n",
            "Epoch: 13, Loss: 0.09561785293718629\n",
            "Epoch: 13, Loss: 0.09556963872370615\n",
            "Epoch: 13, Loss: 0.0955198047682643\n",
            "Epoch: 13, Loss: 0.0954639091274241\n",
            "Epoch: 13, Loss: 0.09543025012827715\n",
            "Epoch: 13, Loss: 0.09538893132211122\n",
            "Epoch: 13, Loss: 0.09541193800171963\n",
            "Epoch: 13, Loss: 0.09544703988078981\n",
            "Epoch: 13, Loss: 0.09538876523285152\n",
            "Epoch: 13, Loss: 0.09549227262941931\n",
            "Epoch: 13, Loss: 0.0954630059920853\n",
            "Epoch: 13, Loss: 0.09556120853459248\n",
            "Epoch: 13, Loss: 0.09551142279651775\n",
            "Epoch: 13, Loss: 0.09542434218119289\n",
            "Epoch: 13, Loss: 0.09534803176504054\n",
            "Epoch: 13, Loss: 0.09538839034651155\n",
            "Epoch: 13, Loss: 0.09554992902772898\n",
            "Epoch: 13, Loss: 0.09555681993410287\n",
            "Epoch: 13, Loss: 0.09551726709166956\n",
            "Epoch: 13, Loss: 0.09552508302625608\n",
            "Epoch: 13, Loss: 0.09552325167199496\n",
            "Epoch: 13, Loss: 0.09544907761480534\n",
            "Epoch: 13, Loss: 0.09539650094241198\n",
            "Epoch: 13, Loss: 0.09545823604539477\n",
            "Epoch: 13, Loss: 0.0954395397726516\n",
            "Epoch: 13, Loss: 0.0953914961111613\n",
            "Epoch: 13, Loss: 0.09534993946417011\n",
            "Epoch: 13, Loss: 0.09546645891706587\n",
            "Epoch: 13, Loss: 0.09542967521300016\n",
            "Epoch: 13, Loss: 0.09534738891632269\n",
            "Epoch: 13, Loss: 0.09529987442328113\n",
            "Epoch: 13, Loss: 0.09526090104645846\n",
            "Epoch: 13, Loss: 0.0952137309140185\n",
            "Epoch: 13, Loss: 0.09515917051826799\n",
            "Epoch: 13, Loss: 0.09507549363310869\n",
            "Epoch: 13, Loss: 0.09507634293592393\n",
            "Epoch: 13, Loss: 0.09501235207327369\n",
            "Epoch: 13, Loss: 0.09502437126289294\n",
            "Epoch: 13, Loss: 0.09507656674091383\n",
            "Epoch: 13, Loss: 0.09498982830920669\n",
            "Epoch: 13, Loss: 0.09502665629873677\n",
            "Epoch: 13, Loss: 0.09493966599812864\n",
            "Epoch: 13, Loss: 0.09500026742068393\n",
            "Epoch: 13, Loss: 0.09498879079334797\n",
            "Epoch: 13, Loss: 0.095023854521149\n",
            "Epoch: 13, Loss: 0.09511203820160402\n",
            "Epoch: 13, Loss: 0.09515811322540174\n",
            "Epoch: 13, Loss: 0.09515932394648328\n",
            "Epoch: 13, Loss: 0.095252758720004\n",
            "Epoch: 13, Loss: 0.0952444966205873\n",
            "Epoch: 13, Loss: 0.095167672629928\n",
            "Epoch: 13, Loss: 0.09508681286998821\n",
            "Epoch: 13, Loss: 0.09504700758356298\n",
            "Epoch: 13, Loss: 0.09501820290950884\n",
            "Epoch: 13, Loss: 0.09497833583608925\n",
            "Epoch: 13, Loss: 0.0949460903528317\n",
            "Epoch: 13, Loss: 0.09505643954170287\n",
            "Epoch: 13, Loss: 0.09499298555377339\n",
            "Epoch: 13, Loss: 0.09497967046099785\n",
            "Epoch: 13, Loss: 0.09500472954989626\n",
            "Epoch: 13, Loss: 0.09497069452684956\n",
            "Epoch: 13, Loss: 0.09496969127262354\n",
            "Epoch: 13, Loss: 0.09488627459915681\n",
            "Epoch: 13, Loss: 0.09493794128392244\n",
            "Epoch: 13, Loss: 0.0949166452000226\n",
            "Epoch: 13, Loss: 0.0949703426437456\n",
            "Epoch: 13, Loss: 0.09496227890909126\n",
            "Epoch: 13, Loss: 0.09493391780086073\n",
            "Epoch: 13, Loss: 0.09486421554250174\n",
            "Epoch: 13, Loss: 0.09484588658470457\n",
            "Epoch: 13, Loss: 0.09495992216159811\n",
            "Epoch: 13, Loss: 0.09488189831083725\n",
            "Epoch: 13, Loss: 0.09484536885699266\n",
            "Epoch: 13, Loss: 0.09477005630956988\n",
            "Epoch: 13, Loss: 0.09468530284349075\n",
            "Epoch: 13, Loss: 0.09466234299882702\n",
            "Epoch: 13, Loss: 0.09459338195742194\n",
            "Epoch: 13, Loss: 0.09475668188332467\n",
            "Epoch: 13, Loss: 0.09479511293420007\n",
            "Epoch: 13, Loss: 0.09471917547478424\n",
            "Epoch: 13, Loss: 0.09467893451381082\n",
            "Epoch: 13, Loss: 0.09463510573824288\n",
            "Epoch: 13, Loss: 0.09459658278238982\n",
            "Epoch: 13, Loss: 0.09457355993843142\n",
            "Epoch: 13, Loss: 0.09458585674922045\n",
            "Epoch: 13, Loss: 0.094654605448754\n",
            "Epoch: 13, Loss: 0.0946055839767816\n",
            "Epoch: 13, Loss: 0.09457942417745167\n",
            "Epoch: 13, Loss: 0.0945244245433613\n",
            "Epoch: 13, Loss: 0.09463521813700068\n",
            "Epoch: 13, Loss: 0.09463446623398918\n",
            "Epoch: 13, Loss: 0.09457226310439092\n",
            "Epoch: 13, Loss: 0.09454836702351951\n",
            "Epoch: 13, Loss: 0.09455849505870038\n",
            "Epoch: 13, Loss: 0.09458336981678281\n",
            "Epoch: 13, Loss: 0.0945239209151409\n",
            "Epoch: 13, Loss: 0.09458555984956489\n",
            "Epoch: 13, Loss: 0.09460550530711104\n",
            "Epoch: 13, Loss: 0.09454221342409441\n",
            "Epoch: 13, Loss: 0.09451020916117076\n",
            "Epoch: 13, Loss: 0.09455096099077497\n",
            "Epoch: 13, Loss: 0.09449970672950761\n",
            "Epoch: 13, Loss: 0.09452454144747494\n",
            "Epoch: 13, Loss: 0.09460506399704252\n",
            "Epoch: 13, Loss: 0.09456892509680706\n",
            "Epoch: 13, Loss: 0.09450965322077423\n",
            "Epoch: 13, Loss: 0.09443318706854933\n",
            "Epoch: 13, Loss: 0.09444630674298175\n",
            "Epoch: 13, Loss: 0.09457866212718534\n",
            "Epoch: 13, Loss: 0.09452099430445791\n",
            "Epoch: 13, Loss: 0.09444985897529361\n",
            "Epoch: 13, Loss: 0.09441182782082225\n",
            "Epoch: 13, Loss: 0.09434334794143678\n",
            "Epoch: 13, Loss: 0.09427539462259016\n",
            "Epoch: 13, Loss: 0.09423304575620776\n",
            "Epoch: 13, Loss: 0.0942602405750734\n",
            "Epoch: 13, Loss: 0.09423500398506483\n",
            "Epoch: 13, Loss: 0.09417694210628601\n",
            "Epoch: 13, Loss: 0.0942113444399387\n",
            "Epoch: 13, Loss: 0.09424300599975592\n",
            "Epoch: 13, Loss: 0.09427499687734252\n",
            "Epoch: 13, Loss: 0.09422480647328445\n",
            "Epoch: 13, Loss: 0.09430650656357942\n",
            "Epoch: 13, Loss: 0.09425449723129137\n",
            "Epoch: 13, Loss: 0.09435597772442385\n",
            "Epoch: 13, Loss: 0.0942804709552539\n",
            "Epoch: 13, Loss: 0.09430746336603225\n",
            "Epoch: 13, Loss: 0.09428754347068856\n",
            "Epoch: 13, Loss: 0.09426027628070575\n",
            "Epoch: 13, Loss: 0.09423552434219117\n",
            "Epoch: 13, Loss: 0.09418048090919295\n",
            "Epoch: 13, Loss: 0.09417513052947832\n",
            "Epoch: 13, Loss: 0.09411247564976415\n",
            "Epoch: 13, Loss: 0.09409277346506252\n",
            "Epoch: 13, Loss: 0.09408772553291632\n",
            "Epoch: 13, Loss: 0.09403113067003152\n",
            "Epoch: 13, Loss: 0.09398940002605108\n",
            "Epoch: 13, Loss: 0.09394281444518901\n",
            "Epoch: 13, Loss: 0.09400702115670373\n",
            "Epoch: 13, Loss: 0.09395246180029447\n",
            "Epoch: 13, Loss: 0.09389689277458052\n",
            "Epoch: 13, Loss: 0.09389575780533596\n",
            "Epoch: 13, Loss: 0.09384955483312321\n",
            "Epoch: 13, Loss: 0.0937868627522003\n",
            "Epoch: 13, Loss: 0.09376823897010719\n",
            "Epoch: 13, Loss: 0.09371195002197107\n",
            "Epoch: 13, Loss: 0.0936856745191154\n",
            "Epoch: 13, Loss: 0.09364845599742247\n",
            "Epoch: 13, Loss: 0.0938175528924047\n",
            "Epoch: 13, Loss: 0.09382571150131211\n",
            "Epoch: 13, Loss: 0.09376776102182316\n",
            "Epoch: 13, Loss: 0.09400742611533577\n",
            "Epoch: 13, Loss: 0.09407204732941422\n",
            "Epoch: 13, Loss: 0.09403650727680515\n",
            "Epoch: 13, Loss: 0.09397144605378834\n",
            "Epoch: 13, Loss: 0.09391678162916962\n",
            "Epoch: 13, Loss: 0.09403230106535881\n",
            "Epoch: 13, Loss: 0.09397657282933916\n",
            "Epoch: 13, Loss: 0.09395543740881036\n",
            "Epoch: 13, Loss: 0.09411511782956142\n",
            "Epoch: 13, Loss: 0.09406497438316268\n",
            "Epoch: 13, Loss: 0.09401230523693642\n",
            "Epoch: 13, Loss: 0.09396179318710259\n",
            "Epoch: 13, Loss: 0.09390238462343077\n",
            "Epoch: 13, Loss: 0.09388582867529169\n",
            "Epoch: 13, Loss: 0.09384708657550316\n",
            "Epoch: 13, Loss: 0.09380113198747336\n",
            "Epoch: 13, Loss: 0.0938128771738085\n",
            "Epoch: 13, Loss: 0.09380155141063477\n",
            "Epoch: 13, Loss: 0.09374448634393949\n",
            "Epoch: 13, Loss: 0.09373783998420383\n",
            "Epoch: 13, Loss: 0.09372315845569064\n",
            "Epoch: 13, Loss: 0.09365254251941911\n",
            "Epoch: 13, Loss: 0.09359848568348555\n",
            "Epoch: 13, Loss: 0.09357375372640131\n",
            "Epoch: 13, Loss: 0.09349646129962759\n",
            "Epoch: 13, Loss: 0.09350885993500707\n",
            "Epoch: 13, Loss: 0.09359280343135644\n",
            "Epoch: 13, Loss: 0.09364886153974498\n",
            "Epoch: 13, Loss: 0.09363093827541205\n",
            "Epoch: 13, Loss: 0.09370799752933633\n",
            "Epoch: 13, Loss: 0.09370122939067396\n",
            "Epoch: 13, Loss: 0.09365991716966666\n",
            "Epoch: 13, Loss: 0.09360220352604313\n",
            "Epoch: 13, Loss: 0.09366395985612688\n",
            "Epoch: 13, Loss: 0.09359016856384196\n",
            "Epoch: 13, Loss: 0.09352850067358941\n",
            "Epoch: 13, Loss: 0.09356633914887147\n",
            "Epoch: 13, Loss: 0.09349608322436732\n",
            "Epoch: 13, Loss: 0.09353610243673505\n",
            "Epoch: 13, Loss: 0.09351832654078382\n",
            "Epoch: 13, Loss: 0.09355125025802015\n",
            "Epoch: 13, Loss: 0.09349930241295305\n",
            "Epoch: 13, Loss: 0.0935255331497696\n",
            "Epoch: 13, Loss: 0.09353584144185999\n",
            "Epoch: 13, Loss: 0.09367236061184746\n",
            "Epoch: 13, Loss: 0.09368186793231333\n",
            "Epoch: 13, Loss: 0.09372166873683699\n",
            "Epoch: 13, Loss: 0.09367838100468431\n",
            "Epoch: 13, Loss: 0.09362603746660854\n",
            "Epoch: 13, Loss: 0.09362400887254547\n",
            "Epoch: 13, Loss: 0.09359259072728643\n",
            "Epoch: 13, Loss: 0.09357728041459078\n",
            "Epoch: 13, Loss: 0.09359238358264334\n",
            "Epoch: 13, Loss: 0.09359035090564337\n",
            "Epoch: 13, Loss: 0.0937565393755228\n",
            "Epoch: 13, Loss: 0.0937230555547263\n",
            "Epoch: 13, Loss: 0.09386844459765901\n",
            "Epoch: 13, Loss: 0.09389353007990107\n",
            "Epoch: 13, Loss: 0.09389386886262804\n",
            "Epoch: 13, Loss: 0.09387908439157362\n",
            "Epoch: 13, Loss: 0.09398581243995763\n",
            "Epoch: 13, Loss: 0.09413613534041708\n",
            "Epoch: 13, Loss: 0.09415865117903323\n",
            "Epoch: 13, Loss: 0.09409116527224584\n",
            "Epoch: 13, Loss: 0.09410333118574163\n",
            "Epoch: 13, Loss: 0.09404416526363496\n",
            "Epoch: 13, Loss: 0.09407710095421096\n",
            "Epoch: 13, Loss: 0.09418161044667862\n",
            "Epoch: 13, Loss: 0.09415560967378048\n",
            "Epoch: 13, Loss: 0.09417145571963952\n",
            "Epoch: 13, Loss: 0.09420216695867369\n",
            "Epoch: 13, Loss: 0.09416281699735686\n",
            "Epoch: 13, Loss: 0.09418833584028394\n",
            "Epoch: 13, Loss: 0.09413253907313235\n",
            "Epoch: 13, Loss: 0.09415197549984226\n",
            "Epoch: 13, Loss: 0.09421419530306271\n",
            "Epoch: 13, Loss: 0.09417125940414481\n",
            "Epoch: 13, Loss: 0.09426591398131887\n",
            "Epoch: 13, Loss: 0.09423578985541474\n",
            "Epoch: 13, Loss: 0.09423057818579703\n",
            "Epoch: 13, Loss: 0.09425441133850589\n",
            "Epoch: 13, Loss: 0.094197525728722\n",
            "Epoch: 13, Loss: 0.0942497108964216\n",
            "Epoch: 13, Loss: 0.09429800511013714\n",
            "Epoch: 13, Loss: 0.09433901959769306\n",
            "Epoch: 13, Loss: 0.0943218986492413\n",
            "Epoch: 13, Loss: 0.09425816364677214\n",
            "Epoch: 13, Loss: 0.09433228263645081\n",
            "Epoch: 13, Loss: 0.0942789096847878\n",
            "Epoch: 13, Loss: 0.09430745829709497\n",
            "Epoch: 13, Loss: 0.09462423072720318\n",
            "Epoch: 13, Loss: 0.09462086786534864\n",
            "Epoch: 13, Loss: 0.09471862564393858\n",
            "Epoch: 13, Loss: 0.09465336354890584\n",
            "Epoch: 13, Loss: 0.09459652563839886\n",
            "Epoch: 13, Loss: 0.09465558971169377\n",
            "Epoch: 13, Loss: 0.09460695484998606\n",
            "Epoch: 13, Loss: 0.09463968407662884\n",
            "Epoch: 13, Loss: 0.0946523468160099\n",
            "Epoch: 13, Loss: 0.09463247038762677\n",
            "Epoch: 13, Loss: 0.0945971138510326\n",
            "Epoch: 13, Loss: 0.0946125938493504\n",
            "Epoch: 13, Loss: 0.09461129147239496\n",
            "Epoch: 13, Loss: 0.09465994523000196\n",
            "Epoch: 13, Loss: 0.09461408806591629\n",
            "Epoch: 13, Loss: 0.09456608749499576\n",
            "Epoch: 13, Loss: 0.09463909811004996\n",
            "Epoch: 13, Loss: 0.09461446799305108\n",
            "Epoch: 13, Loss: 0.09466088986539017\n",
            "Epoch: 13, Loss: 0.09462123343621433\n",
            "Epoch: 13, Loss: 0.09460792119170656\n",
            "Epoch: 13, Loss: 0.09456235980058453\n",
            "Epoch: 13, Loss: 0.09453348742996692\n",
            "Epoch: 13, Loss: 0.09460172485026724\n",
            "Epoch: 13, Loss: 0.09457679045429551\n",
            "Epoch: 13, Loss: 0.0945717127330903\n",
            "Epoch: 13, Loss: 0.09452566913890816\n",
            "Epoch: 13, Loss: 0.09449391537563821\n",
            "Epoch: 13, Loss: 0.0944860349778269\n",
            "Epoch: 13, Loss: 0.09454788481971502\n",
            "Epoch: 13, Loss: 0.09452724557213744\n",
            "Epoch: 13, Loss: 0.09448341973081761\n",
            "Epoch: 13, Loss: 0.09448633938189155\n",
            "Epoch: 13, Loss: 0.09444851190625045\n",
            "Epoch: 13, Loss: 0.09447218844893297\n",
            "Epoch: 13, Loss: 0.09452160273974364\n",
            "Epoch: 13, Loss: 0.09463705428047325\n",
            "Epoch: 13, Loss: 0.09470530738797622\n",
            "Epoch: 13, Loss: 0.09465649272329847\n",
            "Epoch: 13, Loss: 0.09458909066831467\n",
            "Epoch: 13, Loss: 0.09459777802866379\n",
            "Epoch: 13, Loss: 0.09462189360722607\n",
            "Epoch: 13, Loss: 0.0946205659115506\n",
            "Epoch: 13, Loss: 0.09459212408514114\n",
            "Epoch: 13, Loss: 0.09456655278318038\n",
            "Epoch: 13, Loss: 0.09465256568839579\n",
            "Epoch: 13, Loss: 0.09467716224171455\n",
            "Epoch: 13, Loss: 0.09463475017454315\n",
            "Epoch: 13, Loss: 0.09460340916105021\n",
            "Epoch: 13, Loss: 0.09471294219262276\n",
            "Epoch: 13, Loss: 0.0946818640835676\n",
            "Epoch: 13, Loss: 0.09466077618822745\n",
            "Epoch: 13, Loss: 0.09470821436911729\n",
            "Epoch: 13, Loss: 0.09480227273689885\n",
            "Epoch: 13, Loss: 0.0948627364680009\n",
            "Epoch: 13, Loss: 0.09488401809509314\n",
            "Epoch: 13, Loss: 0.09484858379605436\n",
            "Epoch: 13, Loss: 0.0948166560993395\n",
            "Epoch: 13, Loss: 0.09475441437125229\n",
            "Epoch: 13, Loss: 0.09471038291670168\n",
            "Epoch: 13, Loss: 0.09469633890384983\n",
            "Epoch: 13, Loss: 0.09467610339472307\n",
            "Epoch: 13, Loss: 0.09472525060064746\n",
            "Epoch: 13, Loss: 0.09475955274099672\n",
            "Epoch: 13, Loss: 0.09470740735218021\n",
            "Epoch: 13, Loss: 0.09475608875156252\n",
            "Epoch: 13, Loss: 0.09473371183857895\n",
            "Epoch: 13, Loss: 0.09471887611439717\n",
            "Epoch: 13, Loss: 0.09468647769756741\n",
            "Epoch: 13, Loss: 0.09473244257697282\n",
            "Epoch: 13, Loss: 0.0947106107290937\n",
            "Epoch: 13, Loss: 0.09469291590853555\n",
            "Epoch: 13, Loss: 0.09467960255374565\n",
            "Epoch: 13, Loss: 0.09466989794083355\n",
            "Epoch: 13, Loss: 0.09467616704839427\n",
            "Epoch: 13, Loss: 0.09464486606911428\n",
            "Epoch: 13, Loss: 0.09461301950425023\n",
            "Epoch: 13, Loss: 0.09458575814232105\n",
            "Epoch: 13, Loss: 0.094553748511272\n",
            "Epoch: 13, Loss: 0.09460472937117233\n",
            "Epoch: 13, Loss: 0.09469224476500711\n",
            "Epoch: 13, Loss: 0.09465784303518189\n",
            "Epoch: 13, Loss: 0.09460172405831606\n",
            "Epoch: 13, Loss: 0.09459830145581415\n",
            "Epoch: 13, Loss: 0.09462009797053629\n",
            "Epoch: 13, Loss: 0.09456701171065457\n",
            "Epoch: 13, Loss: 0.09458449917464433\n",
            "Epoch: 13, Loss: 0.0945390560103751\n",
            "Epoch: 13, Loss: 0.0946202705326841\n",
            "Epoch: 13, Loss: 0.09455974038003276\n",
            "Epoch: 13, Loss: 0.09452126685634053\n",
            "Epoch: 13, Loss: 0.09448500325446421\n",
            "Epoch: 13, Loss: 0.09448605711567658\n",
            "Epoch: 13, Loss: 0.09453919293890906\n",
            "Epoch: 13, Loss: 0.09448674864048721\n",
            "Epoch: 13, Loss: 0.09457410056637341\n",
            "Epoch: 13, Loss: 0.09470615487587743\n",
            "Epoch: 13, Loss: 0.09478280051022903\n",
            "Epoch: 13, Loss: 0.09473131901679656\n",
            "Epoch: 13, Loss: 0.09470522285013586\n",
            "Epoch: 13, Loss: 0.09469943449272589\n",
            "Epoch: 13, Loss: 0.09472787843786934\n",
            "Epoch: 13, Loss: 0.09470008437530121\n",
            "Epoch: 13, Loss: 0.09467949295902685\n",
            "Epoch: 13, Loss: 0.09469293431630874\n",
            "Epoch: 13, Loss: 0.09467356052817227\n",
            "Epoch: 13, Loss: 0.09463646661337298\n",
            "Epoch: 13, Loss: 0.09458691551295191\n",
            "Epoch: 13, Loss: 0.09462332164302424\n",
            "Epoch: 13, Loss: 0.0946092717994451\n",
            "Epoch: 13, Loss: 0.09457736202984095\n",
            "Epoch: 13, Loss: 0.09458315220200993\n",
            "Epoch: 13, Loss: 0.09453389576579517\n",
            "Epoch: 13, Loss: 0.09450416374708226\n",
            "Epoch: 13, Loss: 0.09445130959144885\n",
            "Epoch: 13, Loss: 0.09442990388461645\n",
            "Epoch: 13, Loss: 0.09438723004043655\n",
            "Epoch: 13, Loss: 0.094432653811692\n",
            "Epoch: 13, Loss: 0.0944567349906074\n",
            "Epoch: 13, Loss: 0.09450017003423733\n",
            "Epoch: 13, Loss: 0.0944573863813904\n",
            "Epoch: 13, Loss: 0.0944183692232984\n",
            "Epoch: 13, Loss: 0.09444093068575371\n",
            "Epoch: 13, Loss: 0.09442069765328592\n",
            "Epoch: 13, Loss: 0.09442424340810028\n",
            "Epoch: 13, Loss: 0.09464283574871428\n",
            "Epoch: 13, Loss: 0.09483853264177657\n",
            "Epoch: 13, Loss: 0.09483354211929285\n",
            "Epoch: 13, Loss: 0.09489289881311433\n",
            "Epoch: 13, Loss: 0.09485265637542273\n",
            "Epoch: 13, Loss: 0.09485959436244651\n",
            "Epoch: 13, Loss: 0.09479705859726165\n",
            "Epoch: 13, Loss: 0.09491176975517374\n",
            "Epoch: 13, Loss: 0.09505650567077509\n",
            "Epoch: 13, Loss: 0.0950432080770053\n",
            "Epoch: 13, Loss: 0.09497919309084284\n",
            "Epoch: 13, Loss: 0.095032650628637\n",
            "Epoch: 13, Loss: 0.09500913422440609\n",
            "Epoch: 13, Loss: 0.09499734756808305\n",
            "Epoch: 13, Loss: 0.09497531361739543\n",
            "Epoch: 13, Loss: 0.09493506146361712\n",
            "Epoch: 13, Loss: 0.0950557596758008\n",
            "Epoch: 13, Loss: 0.09512850341893364\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3b2de5afacf6>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-2e571c9f1dec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    912\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    913\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loss = nn.BCELoss()\n",
        "\n",
        "from transformers import AdamW\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# Setting up optimizer\n",
        "check_point = torch.load(\"check-point.pt\")\n",
        "model.load_state_dict(check_point['model_state_dict'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "optimizer.load_state_dict(check_point['optimizer_state_dict'])\n",
        "num_epochs = 3\n",
        "valid_loss = 0\n",
        "count = 0\n",
        "for epoch in range(12,15):\n",
        "  for input, output in dataloader:\n",
        "    y_pred = model(input)\n",
        "    output = torch.tensor(output, dtype = torch.float32)\n",
        "    l = loss(y_pred, output)\n",
        "    valid_loss += l.item()\n",
        "    count += 1\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    print(f\"Epoch: {epoch}, Loss: {valid_loss/float(count)}\")\n",
        "  torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'dictionary-input': input_train_dataset,\n",
        "            'dictionary-output': output_train_dataset\n",
        "            }, \"check-point.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = pd.read_csv(\"sample_data/testsmall.csv\")\n",
        "data_test[\"text\"] = data_test[\"text\"].apply(clean_data, stop_words = [\"http\", \"com\"], max_length = 1000)\n"
      ],
      "metadata": {
        "id": "JhddyqnXuzKg"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = data_test[\"text\"].tolist()\n",
        "Y_test = data_test[\"sentiment\"].tolist()\n"
      ],
      "metadata": {
        "id": "EOO9ZowaabKa"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test = np.array(Y_test).reshape(-1,1)\n",
        "Y_test = Y_test.tolist()\n",
        "for j in range(len(X_test)):\n",
        "  X_test[j] = torch.tensor(input_train_dataset.lookup_indices(X_test[j]))\n",
        "  Y_test[j] = torch.tensor(output_train_dataset.lookup_indices(Y_test[j]))\n",
        "X_test = nn.utils.rnn.pad_sequence(X_test, padding_value = 0, batch_first = True)\n",
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flan_AkuYkn3",
        "outputId": "f1b6ec7c-698f-46ea-84b1-f721aa117271"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3197, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "ZWdgO-Ji6XjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d228f856-8b50-4f93-8089-30d4710118e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0.,  ..., 1., 1., 1.])\n",
            "tensor([0., 0., 0.,  ..., 1., 1., 1.])\n",
            "86.73756718635559\n"
          ]
        }
      ],
      "source": [
        "Y_test = torch.tensor(Y_test, dtype = torch.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_pred = model(X_test)\n",
        "  y_pred_cls = y_pred.round()\n",
        "  y_pred_cls = y_pred_cls.reshape(-1)\n",
        "  print(y_pred_cls)\n",
        "  acc = y_pred_cls.eq(Y_test).sum() / float(3197)\n",
        "  print(Y_test)\n",
        "  print(acc.item()*100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_point = torch.load(\"check-point.pt\")\n",
        "model.load_state_dict(check_point['model_state_dict'])\n",
        "nlp_input = \"I not really like the movie. The movie was normal. The actors were awesome but not good\"\n",
        "nlp_input = clean_data(nlp_input, [\"http\", \"com\"], 1000)\n",
        "print(nlp_input)\n",
        "input = input_train_dataset.lookup_indices(nlp_input)\n",
        "for m in range(1000 - len(nlp_input)):\n",
        "  input.append(0)\n",
        "with torch.no_grad():\n",
        "  input = torch.tensor(input)\n",
        "  print(model(input))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKxdcs_ZdUGo",
        "outputId": "bef871d9-4a21-4b40-9b98-268a1b4fefa5"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'not', 'really', 'like', 'the', 'movie', 'the', 'movie', 'wa', 'normal', 'the', 'actor', 'were', 'awesome', 'but', 'not', 'good']\n",
            "tensor([[0.4773]])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}